{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96d71ce2-2e81-45ef-a494-0a07a03554bc",
   "metadata": {},
   "source": [
    "# Split data at a given timestamp\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/google/temporian/blob/last-release/docs/src/recipes/split_timestamp.ipynb)\n",
    "\n",
    "This recipe can be used to split an `EventSet` in two or more subsets at fixed timestamps.\n",
    "\n",
    "This exact same procedure applies to multi-index data or the default single empty index.\n",
    "\n",
    "For example, to train a machine learning forecasting model, the data usually needs to be split into train, validation and test `EventSets` at some fixed timestamps in that respective order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972cd99f-6c1e-4655-8bfe-767e547d6014",
   "metadata": {},
   "source": [
    "## Example data\n",
    "\n",
    "In this toy example we'll use two separate indexes, but this also applies to any number of indexes as mentioned above.\n",
    "\n",
    "The second index has 2 more data points from the previous year. Both of them finish at the same date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28abb293-e542-4540-9c65-3cf1c89c4c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import temporian as tp\n",
    "\n",
    "sample_data = pd.DataFrame(\n",
    "    data=[\n",
    "        # date,  index=1, feature\n",
    "        [\"2020-01-01\", 1, 1.0],\n",
    "        [\"2020-02-01\", 1, 2.0],\n",
    "        [\"2020-03-01\", 1, 3.0],\n",
    "        [\"2020-04-01\", 1, 4.0],\n",
    "        [\"2020-05-01\", 1, 5.0],\n",
    "        [\"2020-06-01\", 1, 6.0],\n",
    "        # date,  index=2, feature\n",
    "        [\"2019-11-01\", 2, -20.0],\n",
    "        [\"2019-12-01\", 2, -10.0],\n",
    "        [\"2020-01-01\", 2, 10.0],\n",
    "        [\"2020-02-01\", 2, 20.0],\n",
    "        [\"2020-03-01\", 2, 30.0],\n",
    "        [\"2020-04-01\", 2, 40.0],\n",
    "        [\"2020-05-01\", 2, 50.0],\n",
    "        [\"2020-06-01\", 2, 60.0],\n",
    "    ],\n",
    "    columns=[\n",
    "        \"timestamp\",\n",
    "        \"idx\",\n",
    "        \"feature\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "sample_evset = tp.from_pandas(sample_data, indexes=[\"idx\"])\n",
    "sample_evset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04cc1b4-ac53-4f41-ad59-9f98fa0f0210",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "We want to split this into 3 separate `EventSets` as follows:\n",
    "* **Train** data: all data points until `2020-03-01` (including it)\n",
    "* **Validation**: after training and until `2020-05-01` (including it)\n",
    "* **Test**: data after `2020-05-01` (not including it)\n",
    "\n",
    "So the proposed steps are:\n",
    "1. Convert the timestamps of events into a feature.\n",
    "2. Filter train/validation/test by comparing the timestamps feature to the defined boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e85cea-9814-40cc-8ffd-dfc87a5e8716",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Define boundaries for train/validation/test\n",
    "train_until = datetime(2020, 3, 1)\n",
    "val_until = datetime(2020, 5, 1)\n",
    "one_milisecond = timedelta(milliseconds=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d52487-3006-4bf9-9c4c-dad3d47db300",
   "metadata": {},
   "source": [
    "### Split based on timestamps\n",
    "\n",
    "Using before and after we can split the dataset. Notice that both functions are \n",
    "non-inclusive so we need to add one milisecond in one of the cases so that the \n",
    "values in the limit are included in one of the sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1afd17-ccfa-4bd8-b0bf-406fa098aad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_evset = sample_evset.before(train_until + one_milisecond)\n",
    "val_evset = sample_evset.after(train_until).before(val_until + one_milisecond)\n",
    "test_evset = sample_evset.after(val_until)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09775af5-c18e-4edf-b7dd-038772a63f50",
   "metadata": {},
   "source": [
    "## Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03af0fc5-9fe4-48b2-80c3-587dec522bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_evset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26cf689-cf12-40de-93b9-c0b13e0b27d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_evset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668e85b3-f318-4669-8b23-1441b3182ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_evset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
