{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "4e767688-0f90-47a7-baf0-b8042e282746",
      "metadata": {},
      "source": [
        "# User Guide\n",
        "\n",
        "This is a complete tour of Temporian's capabilities. For a brief introduction to how the library works, please refer to [3 minutes to Temporian](./3_minutes).\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "d2b71b95-5268-46ca-98e3-83b473f9b518",
      "metadata": {},
      "source": [
        "## What is temporal data?\n",
        "\n",
        "In Temporian, there is only one type of data: **multivariate multi-index time sequences** (MMITS). MMITS extends many commonly used data formats such as time-series and transactions to allow multi-variate data, non-uniform sampling, non-aligned sampling, and hierarchically-structured data. In that, MMITSs are particularly well suited to represent classical time-series, but also transactions, logs, sparse events, asynchronous measurements, and hierarchical records.\n",
        "\n",
        "<!-- TODO: add plot -->"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "d64627bf",
      "metadata": {
        "cell_marker": "\"\"\"",
        "lines_to_next_cell": 0
      },
      "source": [
        "## Events and EventSets\n",
        "\n",
        "The unit of data in Temporian is referred to as an _event_. An event consists of a timestamp and a set of feature values.\n",
        "\n",
        "Here is an example of an event:\n",
        "\n",
        "```\n",
        "timestamp: 2023-02-05\n",
        "feature_1: 0.5\n",
        "feature_2: \"red\"\n",
        "feature_3: 10\n",
        "```\n",
        "\n",
        "Events are not handled individually. Instead, events are grouped together into [EventSet][temporian.EventSet]s. When representing an `EventSet`, it is convenient to group similar features together and to sort them according to the timestamps in increasing order.\n",
        "\n",
        "Here is an example of an `EventSet` containing four events and three features:\n",
        "\n",
        "```\n",
        "timestamp: [04-02-2023, 06-02-2023, 07-02-2023, 07-02-2023]\n",
        "feature_1: [0.5, 0.6, NaN, 0.9]\n",
        "feature_2: [\"red\", \"blue\", \"red\", \"blue\"]\n",
        "feature_3:  [10, -1, 5, 5]\n",
        "```\n",
        "\n",
        "**Remarks:**\n",
        "\n",
        "- All values for a given feature are of the same data type. For instance, `feature_1` is float64 while `feature_2` is a string.\n",
        "- Many operators interpret the value NaN (for _not a number_) as missing.\n",
        "- Timestamps are not necessarily uniformly sampled.\n",
        "- The same timestamp can be repeated.\n",
        "- The events withing an EventSet are sampled synchronously. However, different EventSets might be sampled differently.\n",
        "\n",
        "In the next code examples, variables with names like `evset` refer to an `EventSet`.\n",
        "\n",
        "You can create an `EventSet` as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d23b4c0",
      "metadata": {},
      "outputs": [],
      "source": [
        "import temporian as tp\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "evset = tp.event_set(\n",
        "\ttimestamps=[\"2023-02-04\",\"2023-02-06\",\"2023-02-07\",\"2023-02-07\"],\n",
        "\tfeatures={\n",
        "        \"feature_1\": [0.5, 0.6, np.nan, 0.9],\n",
        "        \"feature_2\": [\"red\", \"blue\", \"red\", \"blue\"],\n",
        "        \"feature_3\":  [10, -1, 5, 5],\n",
        "\t}\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "3678cc72",
      "metadata": {
        "cell_marker": "\"\"\"",
        "lines_to_next_cell": 0
      },
      "source": [
        "\n",
        "`EventSets` can be printed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17c712f6",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(evset)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "a09dfdad",
      "metadata": {
        "cell_marker": "\"\"\"",
        "lines_to_next_cell": 0
      },
      "source": [
        "`EventSets` can be plotted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3f29b64",
      "metadata": {},
      "outputs": [],
      "source": [
        "evset.plot()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "fe507137-0c0f-4533-a75d-008352a2566b",
      "metadata": {},
      "source": [
        "\n",
        "**Note:** You'll learn how to create an `EventSet` using other data sources such as pandas DataFrames later.\n",
        "\n",
        "Events can carry various meanings. For instance, events can represent **regular measurements**. Suppose an electronic thermometer that generates temperature measurements every minute. This could be an `EventSet` with one feature called `temperature`. In this scenario, the temperature can change between two measurements. However, for most practical uses, the most recent measurement will be considered the current temperature.\n",
        "\n",
        "<!-- TODO: Temperature plot -->\n",
        "\n",
        "Events can also represent the _occurrence_ of sporadic phenomena. Suppose a sales recording system that records client purchases. Each time a client makes a purchase (i.e., each transaction), a new event is created.\n",
        "\n",
        "<!-- TODO: Sales plot -->\n",
        "\n",
        "You will see that Temporian is agnostic to the semantics of events, and that often, you will mix together measurements and occurrences. For instance, given the _occurrence_ of sales from the previous example, you can compute daily sales (which is a _measurement_).\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "e7a88b45-bef7-46ac-88b8-f376cc14ee88",
      "metadata": {},
      "source": [
        "## Operators\n",
        "\n",
        "Processing operations are performed by **operators**. For instance, the `tp.simple_moving_average()` operator computes the [simple moving average](https://en.wikipedia.org/wiki/Moving_average) of each feature in an `EventSet`.\n",
        "\n",
        "The list of all operators is available in the [API Reference](../reference/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0c059c3-1412-47d5-8f21-8c034f16a551",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create an event set with a random walk\n",
        "np.random.seed(1)\n",
        "random_walk = np.cumsum(np.random.choice([-1.0, 0.0, 1.0], size=1000))\n",
        "\n",
        "evset = tp.event_set(\n",
        "\ttimestamps=np.linspace(0,10, num=1000),\n",
        "\tfeatures={\"value\": random_walk}\n",
        ")\n",
        "\n",
        "# Compute a simple moving average\n",
        "result = tp.simple_moving_average(evset, window_length=1)\n",
        "\n",
        "# Plot the results\n",
        "tp.plot([evset, result]) "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "0dd8a9a5-19b4-4898-b5af-794dbd4ac1eb",
      "metadata": {},
      "source": [
        "## Eager mode vs Graph mode\n",
        "\n",
        "Temporian has two execution modes: **eager** and **graph**. In eager mode, operators are applied immediately. This mode is useful for learning Temporian, for iterative and interactive development, and for lightweight/small data use cases where performance isn't a priority.\n",
        "\n",
        "In graph mode, operators are combined together into \"Temporian programs\" before being executed. Graph mode is more efficient and it consumes less memory. Temporian programs can be saved, inspected, and distributed by users.\n",
        "\n",
        "Migrating a Temporian program from eager to graph mode is easy and requires little work. Most of the time, adding a `@tp.compile` annotation is enough. Therefore, it is recommended to develop programs in eager mode and then to productize them in graph mode.\n",
        "\n",
        "Next, we see a the same program written three times: First, in eager mode, then in graph mode using `@tp.compile`, and finally in graph mode without `@tp.compile`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5405837-c801-40e9-8b41-4d4dc901d429",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Eager mode\n",
        "#\n",
        "# Note: This Temporian program contains three operators: two \"simple_moving_average\" and one \"tp.substract\" operators.\n",
        "result = tp.simple_moving_average(evset, window_length=0.5) - tp.simple_moving_average(evset, window_length=1.0)\n",
        "result.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c854408-0804-4435-8d44-f521ef1b379e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Graph mode with @tp.compile\n",
        "\n",
        "@tp.compile\n",
        "def my_function(x):\n",
        "    return tp.simple_moving_average(x, window_length=0.5) - tp.simple_moving_average(x, window_length=1.0)\n",
        "\n",
        "result = my_function(evset)\n",
        "    \n",
        "result.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4aa008f-aa8e-486f-a96c-854fb5b2bd83",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Graph model without @tp.compile\n",
        "\n",
        "input_node = tp.input_node([(\"value\", tp.float64)])\n",
        "# Or input_node = tp.input_node(evset.schema.features)\n",
        "\n",
        "result_node = tp.simple_moving_average(input_node, window_length=0.5) - tp.simple_moving_average(input_node, window_length=1.0)\n",
        "result = tp.run(result_node, {input_node: evset}, verbose=1)\n",
        "    \n",
        "result.plot()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "a6a5a017-9dbe-4782-bc73-9b278ec622b0",
      "metadata": {},
      "source": [
        "## More on graph mode\n",
        "\n",
        "**Remark:** While you will likely use the graph mode with `@tp.compile` , it is useful for you to understand the graph model without `@tp.compile`.\n",
        "\n",
        "A Temporian program is a graph of [EventSetNode][temporian.EventSetNodes]s connecting operators. A graph is executed with the function `tp.run(<outputs>, <inputs>)`.\n",
        "\n",
        "<img src=\"https://github.com/google/temporian/blob/main/docs/src/assets/eager_and_graph.svg\" width=\"100%\" alt=\"eager vs graph mode\">\n",
        "\n",
        "The `<outputs>` can be specified as an `EventSetNode`, a list of `EventSetNodes`, or a dictionary of names to `EventSetNodes`, and the result of `tp.run()` will be of the same type. For example, if `<outputs>` is a list of three `EventSetNodes`, the result will be a list of the three corresponding `EventSets`.\n",
        "\n",
        "The `<inputs>` can be specified as:\n",
        "\n",
        "- A dictionary of `EventSetNodes` to `EventSets`, or \n",
        "- A dictionary of names to `EventSets`, or,\n",
        "- A list of `EventSets`, or\n",
        "- A single `EventSet`\n",
        "\n",
        "This lets Temporian know the `EventSetNodes` of the graph that each input `EventSet` corresponds to. If `<inputs>` is a dictionary of names to `EventSets`, the names must match the names of `EventSetNodes` in the graph.  If `<inputs>` is a list or a single `EventSet`, the names of those `EventSets` must do the same. If we specify the inputs as a dictionary, we could skip passing a name to `a_evset`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd4142a0-df47-4ca3-aafe-7a105b4f2deb",
      "metadata": {},
      "outputs": [],
      "source": [
        "input_node = tp.input_node([(\"value\", tp.float64)])\n",
        "result_1_node = tp.simple_moving_average(input_node, window_length=0.5)\n",
        "result_2_node = tp.simple_moving_average(input_node, window_length=1.0)\n",
        "result_3_node = result_1_node - result_2_node\n",
        "\n",
        "result = tp.run([result_1_node,result_2_node, result_3_node], {input_node: evset})\n",
        "    \n",
        "print(result)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "32dd49a8-8847-4df1-be17-b844b92f4211",
      "metadata": {},
      "source": [
        "**Remarks:**\n",
        "\n",
        "- It's important to distinguish between a `tp.EventSet`, such as `evset`, that contains data, and a `tp.EventSetNode`, like `input_node`, that connect operators together and compose the computation graph, but do not contain data.\n",
        "- No computation is performed when defining the graph (i.e., when calling the operator functions). All computation is done during `tp.run()`.\n",
        "- In `tp.run()`, the second argument defines a mapping between input `EventSetNodes` and `EventSets`. If all necessary input `EventSetNodes` are not fed, an error will be raised.\n",
        "- In most cases you will only pass `EventSets` that correspond to the graph's input `EventSetNodes`, but Temporian also supports passing `EventSets` to intermediate `EventSetNodes` in the graph."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "c7e808b2-4091-447a-a6a5-66fcf5f037a9",
      "metadata": {},
      "source": [
        "The `@tp.compile` annotation takes a function inputing and outputing `tp.EventSetNode`, and automatically calls `tp.run` on the result of the function if a `tp.EventSet` is provided as input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0b0220b-9869-454c-8f3b-afeabaca06bc",
      "metadata": {},
      "outputs": [],
      "source": [
        "@tp.compile\n",
        "def my_function(x : tp.EventSetNode) -> tp.EventSetNode:\n",
        "    return tp.simple_moving_average(x, window_length=0.5)\n",
        "\n",
        "# Feeding an EventSet\n",
        "input_evset = tp.event_set(timestamps=[1, 2, 3],features={\"value\": [5., 6., 7.]})\n",
        "assert isinstance(my_function(input_evset), tp.EventSet)\n",
        "\n",
        "# Feeding an EventSetNode\n",
        "input_node = tp.input_node([(\"value\", tp.float64)])\n",
        "assert isinstance(my_function(input_node), tp.EventSetNode)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "c0f02853-718f-4c9e-8945-b25e74b548ae",
      "metadata": {},
      "source": [
        "Importantly, variables in a `tp.compile` function are `EventSetNode` and not `EventSet`. Therefore, you cannot directly access the event set data.\n",
        "\n",
        "In addition, the compiled function execution first generates the graph. The graph is then executed. In the next example, the compiled function generates a graph with 10 operators."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "945d8f39-18ad-44df-a4d2-9d8986e7825b",
      "metadata": {},
      "outputs": [],
      "source": [
        "@tp.compile\n",
        "def my_function(x : tp.EventSetNode) -> tp.EventSetNode:\n",
        "    for i in range(10):\n",
        "        x = tp.simple_moving_average(x, window_length=i+1)\n",
        "    return x"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "4c46c4ee-a8ff-4b9b-9ced-acbee202d0a3",
      "metadata": {},
      "source": [
        "You can create a compiled function with a `if`. However, the condition of the `if` cannot depend on the EventSet data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "941a5fc4-edfc-4fba-8bc8-22f3a7387e91",
      "metadata": {},
      "outputs": [],
      "source": [
        "@tp.compile\n",
        "def my_function(x : tp.EventSetNode, a:bool) -> tp.EventSetNode:\n",
        "    if a:\n",
        "        return tp.rename(x, \"a_branch\")\n",
        "    else:\n",
        "        return tp.rename(x, \"non_a_branch\")\n",
        "\n",
        "print(my_function(input_evset, a=True).schema.features)\n",
        "\n",
        "print(my_function(input_evset, a=False).schema.features)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "3bf624e6-6b1c-4806-8024-8beebd30fc0b",
      "metadata": {},
      "source": [
        "If you want to create a program conditional on EventSet data, you can use a `tp.filter`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9ab68f3-91a6-445e-99c2-7f2379185f21",
      "metadata": {},
      "outputs": [],
      "source": [
        "@tp.compile\n",
        "def my_function(x : tp.EventSetNode) -> tp.EventSetNode:\n",
        "    return tp.filter(x[\"value\"], x[\"condition\"])\n",
        "\n",
        "my_function(tp.event_set(\n",
        "\ttimestamps=[1,2,3],\n",
        "\tfeatures={\n",
        "        \"value\": [10, 11, 12],\n",
        "        \"condition\":[True, True, False]}\n",
        "))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "c7ef8b32-a08d-46e2-aa8e-5cad3d5421e0",
      "metadata": {},
      "source": [
        "To simplify its usage when the graph contains a single output `EventSetNode`, `node.run(...)` is equivalent to `tp.run(node, ...)`."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "afa9c5d2-1efe-440d-bf45-366c0b389b5a",
      "metadata": {},
      "source": [
        "\n",
        "<!-- TODO\n",
        "# Not implemented yet:\n",
        "# d_evset = tp.run(d_node, {\"a\": a_evset})\n",
        "# d_evset = tp.run(d_node, [a_evset])\n",
        "# d_evset = tp.run(d_node, a_evset)\n",
        "# d_evset = d_node.run({\"a\": a_evset})\n",
        "# d_evset = d_node.run([a_evset])\n",
        "# d_evset = d_node.run(a_evset)\n",
        "-->\n",
        "\n",
        "**Warning:** It is more efficient to run multiple output `EventSetNodes` together with `tp.run()` than to run them separately with `node_1.run(...)`, `node_2.run(...)`, etc."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "d78f320b",
      "metadata": {
        "cell_marker": "\"\"\"",
        "lines_to_next_cell": 0
      },
      "source": [
        "Previously, we defined the input of the graph with `tp.input_node()`. This way of listing features manually and their respective data type is cumbersome.\n",
        "\n",
        "If an `EventSet` is available (i.e., data is available) this step can be changed to use `evset.node()` instead, which will return an `EventSetNode` that is compatible with it. This is especially useful when creating `EventSets` from existing data, such as pandas DataFrames or CSV files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4fc33b0",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "outputs": [],
      "source": [
        "# Define an EventSet.\n",
        "a_evset = tp.event_set(\n",
        "\ttimestamps=[0, 1, 2],\n",
        "\tfeatures={\n",
        "        \"feature_1\": [1.0, 2.0, 3.0],\n",
        "        \"feature_2\": [\"hello\", \"little\", \"dog\"],\n",
        "        \"feature_3\": [\"A\", \"A\", \"B\"],\n",
        "\t}\n",
        ")\n",
        "\n",
        "# The following three statements are (almost) equivalent.\n",
        "a_node = tp.input_node(\n",
        "    features=[\n",
        "        (\"feature_1\", tp.float64),\n",
        "        (\"feature_2\", tp.str_),\n",
        "    ],\n",
        "    indexes=[(\"feature_3\", tp.str_)])\n",
        "\n",
        "a_node = tp.input_node(features=a_evset.schema.features,\n",
        "                       indexes=a_evset.schema.indexes)\n",
        "    \n",
        "a_node = a_evset.node()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "b73d3011",
      "metadata": {
        "cell_marker": "\"\"\"",
        "lines_to_next_cell": 0
      },
      "source": [
        "\n",
        "## Time units\n",
        "\n",
        "In Temporian, times are always represented by a float64 value. Users have the freedom to choose the semantic to this value. For example, the time can be the number of nanoseconds since the start of the day, the number of cycles of a process, the number of years since the big bang, or the number of seconds since January 1, 1970, at 00:00:00 UTC, also known as Unix or POSIX time.\n",
        "\n",
        "To ease the feature engineering of dates, Temporian contains a set of _calendar operators_. These operators specialize in creating features from dates and datetimes. For instance, the `tp.calendar_hour()` operator returns the hour of the date in the range `0-23`.\n",
        "\n",
        "Calendar operators require the time in their inputs to be Unix time, so applying them on non-Unix timestamps will raise errors. Temporian can sometimes automatically recognize if input timestamps correspond to Unix time (e.g. when an `EventSet` is created from a pandas DataFrame with a datetime column, or when passing a list of datetime objects as timestamps in `EventSet`'s constructor). If creating `EventSets` manually and passing floats directly to `timestamps`, you need to explicitly specify whether they correspond to Unix times or not via the `is_unix_timestamp` argument."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92ec9711",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "outputs": [],
      "source": [
        "a_evset = tp.event_set(\n",
        "    timestamps=[\n",
        "        pd.to_datetime(\"Monday Mar 13 12:00:00 2023\", utc=True),\n",
        "        pd.to_datetime(\"Tuesday Mar 14 12:00:00 2023\", utc=True),\n",
        "        pd.to_datetime(\"Friday Mar 17 00:00:01 2023\", utc=True),\n",
        "    ],\n",
        "    features={\n",
        "        \"feature_1\": [1, 2, 3],\n",
        "        \"feature_2\": [\"a\", \"b\", \"c\"],\n",
        "    },\n",
        ")\n",
        "a_node = a_evset.node()\n",
        "b_node = tp.glue(a_node, tp.calendar_day_of_week(a_node))\n",
        "b_node.run(a_evset)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "7380c9c7",
      "metadata": {
        "cell_marker": "\"\"\"",
        "lines_to_next_cell": 0
      },
      "source": [
        "\n",
        "Temporian accepts time inputs in various formats, including integer, float, Python date or datetime, NumPy datetime, and pandas datetime. Date and datetime objects are internally converted to floats as Unix time in seconds, compatible with the calendar operators.\n",
        "\n",
        "Operators can take _durations_ as input arguments. For example, the simple moving average operator takes a `window_length` argument. Temporian exposes several utility functions to help creating those duration arguments when using Unix timestamps:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "508c3f0c",
      "metadata": {},
      "outputs": [],
      "source": [
        "a = tp.input_node(features=[(\"feature_1\", tp.float64)])\n",
        "\n",
        "# Define a 1-day moving average.\n",
        "b = tp.simple_moving_average(a, window_length=tp.duration.days(1))\n",
        "\n",
        "# Equivalent.\n",
        "b = tp.simple_moving_average(a, window_length=24 * 60 * 60)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "6c99993c",
      "metadata": {
        "cell_marker": "\"\"\"",
        "lines_to_next_cell": 0
      },
      "source": [
        "\n",
        "## Plotting\n",
        "\n",
        "Data visualization is crucial for gaining insights into data and the system it represents. It also helps in detecting unexpected behavior and issues, making debugging and iterative development easier.\n",
        "\n",
        "Temporian provides two plotting functions for data visualization: `evset.plot()` and `tp.plot()`.\n",
        "\n",
        "The `evset.plot()` function is shorter to write and is used for displaying a single `EventSet`, while the `tp.plot()` function is used for displaying multiple `EventSets` together. This function is particularly useful when `EventSets` are indexed (see [Index, horizontal and vertical operators](#indexes-horizontal-and-vertical-operators)) or have different samplings (see [Sampling](#sampling)).\n",
        "\n",
        "Here's an example of using the `evset.plot()` function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbf42f42",
      "metadata": {},
      "outputs": [],
      "source": [
        "evset = tp.event_set(\n",
        "\ttimestamps=[1, 2, 3, 4, 5],\n",
        "\tfeatures={\n",
        "        \"feature_1\": [0.5, 0.6, 0.4, 0.4, 0.9],\n",
        "        \"feature_2\": [\"red\", \"blue\", \"red\", \"blue\", \"green\"]\n",
        "    }\n",
        ")\n",
        "evset.plot()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "39dc9a92",
      "metadata": {
        "cell_marker": "\"\"\"",
        "lines_to_next_cell": 0
      },
      "source": [
        "\n",
        "By default, the plotting style is selected automatically based on the data.\n",
        "\n",
        "For example, uniformly sampled numerical features (i.e., time series) are plotted with a continuous line, while non-uniformly sampled values are plotted with markers. Those and other behaviors can be controlled via the function's arguments.\n",
        "\n",
        "Here's an example of using the `evset.plot()` function with options:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82552e04",
      "metadata": {},
      "outputs": [],
      "source": [
        "figure = evset.plot(\n",
        "    style=\"marker\",\n",
        "    width_px=400,\n",
        "    min_time=2,\n",
        "    max_time=10,\n",
        "    return_fig=True,\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "37bd0475",
      "metadata": {
        "cell_marker": "\"\"\"",
        "lines_to_next_cell": 0
      },
      "source": [
        "\n",
        "The plots are static images by default. However, interactive plotting can be very powerful. To enable interactive plotting, use `interactive=True`. Note that interactive plotting requires the `bokeh` Python library to be installed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37feddd0",
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install bokeh -q\n",
        "\n",
        "evset.plot(interactive=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "cf4d0c27",
      "metadata": {
        "cell_marker": "\"\"\"",
        "lines_to_next_cell": 0
      },
      "source": [
        "\n",
        "## Feature naming\n",
        "\n",
        "Each feature is identified by a name, and the list of features is available through the `features` property of an `EventSetNode`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38ff0e20",
      "metadata": {},
      "outputs": [],
      "source": [
        "events = tp.event_set(\n",
        "\ttimestamps=[1,2,3,4,5],\n",
        "\tfeatures={\n",
        "\t    \"feature_1\": [0.5, 0.6, 0.4, 0.4, 0.9],\n",
        "\t    \"feature_2\": [1.0, 2.0, 3.0, 2.0, 1.0]}\n",
        "    )\n",
        "node = events.node()\n",
        "print(node.features)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "2cd29020",
      "metadata": {
        "cell_marker": "\"\"\"",
        "lines_to_next_cell": 0
      },
      "source": [
        "\n",
        "Most operators do not change the input feature's names."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "838449d4",
      "metadata": {},
      "outputs": [],
      "source": [
        "tp.moving_sum(node, window_length=10).features"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "b70cc298",
      "metadata": {
        "cell_marker": "\"\"\"",
        "lines_to_next_cell": 0
      },
      "source": [
        "\n",
        "Some operators combine two input features with different names, in which case the output name is also combined."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b10fdec3",
      "metadata": {},
      "outputs": [],
      "source": [
        "result = node[\"feature_1\"] * node[\"feature_2\"]\n",
        "result.features"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "87731369",
      "metadata": {
        "cell_marker": "\"\"\"",
        "lines_to_next_cell": 0
      },
      "source": [
        "\n",
        "The calendar operators don't depend on input features but on the timestamps, so the output feature name doesn't\n",
        "relate to the input feature names."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4182d3f8",
      "metadata": {},
      "outputs": [],
      "source": [
        "date_events = tp.event_set(\n",
        "\ttimestamps=[\"2020-02-15\", \"2020-06-20\"],\n",
        "\tfeatures={\"some_feature\": [10, 20]}\n",
        "    )\n",
        "date_node = date_events.node()\n",
        "print(tp.calendar_month(date_node).features)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "61127d7f",
      "metadata": {
        "cell_marker": "\"\"\"",
        "lines_to_next_cell": 0
      },
      "source": [
        "\n",
        "You can modify feature names using the `tp.rename()` and `tp.prefix()` operators. `tp.rename()` changes the name of features, while `tp.prefix()` adds a prefix in front of existing feature names. Note that they do not modify the content of the input `EventSetNode`, but return a new `EventSetNode` with the modified feature names."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc36bc1f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Rename a single feature.\n",
        "renamed_f1 = tp.rename(node[\"feature_1\"], \"renamed_1\")\n",
        "print(renamed_f1.features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a44f6e7a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Rename all features.\n",
        "renamed_node = tp.rename(node,\n",
        "    {\"feature_1\": \"renamed_1\", \"feature_2\": \"renamed_2\"}\n",
        ")\n",
        "print(renamed_node.features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af6103fc",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prefix a single feature.\n",
        "prefixed_f1 = tp.prefix(\"prefixed.\", node[\"feature_1\"])\n",
        "print(prefixed_f1.features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3126cbed",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prefix all features.\n",
        "prefixed_node = tp.prefix(\"prefixed.\", node)\n",
        "print(prefixed_node.features)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "085e79c3",
      "metadata": {
        "cell_marker": "\"\"\"",
        "lines_to_next_cell": 0
      },
      "source": [
        "\n",
        "It is recommended to use `tp.rename()` and `tp.prefix()` to organize your data, and avoid duplicated feature names."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "852abbdd",
      "metadata": {},
      "outputs": [],
      "source": [
        "sma_7_node = tp.prefix(\"sma_7.\", tp.simple_moving_average(node, tp.duration.days(7)))\n",
        "sma_14_node = tp.prefix(\"sma_14.\", tp.simple_moving_average(node, tp.duration.days(14)))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "ac25eb4a",
      "metadata": {
        "cell_marker": "\"\"\"",
        "lines_to_next_cell": 0
      },
      "source": [
        "\n",
        "The `tp.glue()` operator can be used to concatenate different features into a single `EventSetNode`, but it will fail if two features with the same name are provided. The following pattern is commonly used in Temporian programs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7d85e33",
      "metadata": {},
      "outputs": [],
      "source": [
        "result = tp.glue(\n",
        "    tp.prefix(\"sma_7.\", tp.simple_moving_average(node, tp.duration.days(7))),\n",
        "    tp.prefix(\"sma_14.\", tp.simple_moving_average(node, tp.duration.days(14))),\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "749df3cc",
      "metadata": {
        "cell_marker": "\"\"\"",
        "lines_to_next_cell": 0
      },
      "source": [
        "\n",
        "## Casting\n",
        "\n",
        "Temporian is strict on feature data types (also called dtype). This means that often, you cannot perform operations between features of different types. For example, you cannot subtract a `tp.float32` and a `tp.float64`. Instead, you must manually cast the features to the same type before performing the operation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1276be1",
      "metadata": {},
      "outputs": [],
      "source": [
        "node = tp.input_node(features=[(\"f1\", tp.float32), (\"f2\", tp.float64)])\n",
        "added = tp.cast(node[\"f1\"], tp.float64) + node[\"f2\"]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "d45a37bb",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "source": [
        "\n",
        "Casting is especially useful to reduce memory usage. For example, if a feature only contains values between 0 and 10000, using `tp.int32` instead of `tp.int64` will halve memory usage. These optimizations are critical when working with large datasets.\n",
        "\n",
        "Casting can also be a necessary step before calling operators that only accept certain input data types.\n",
        "\n",
        "Note that in Python, the values `1.0` and `1` are respectively `float64` and `int64`.\n",
        "\n",
        "Temporian supports data type casting through the `tp.cast()` operator. Destination data types can be specified in three different ways:\n",
        "\n",
        "1. Single data type: converts all input features to the same destination data type.\n",
        "\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e3ee4c4",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "outputs": [],
      "source": [
        "node.features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c2444ba",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(tp.cast(node, tp.str_).features)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "59c449d9",
      "metadata": {
        "cell_marker": "\"\"\"",
        "lines_to_next_cell": 0
      },
      "source": [
        "\n",
        "2. Feature name to data type mapping: converts each feature (specified by name) to a specific data type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05ee00a7",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(tp.cast(node, {\"f1\": tp.str_, \"f2\": tp.int64}).features)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "3f85a531",
      "metadata": {
        "cell_marker": "\"\"\"",
        "lines_to_next_cell": 0
      },
      "source": [
        "\n",
        "3. Data type to data type mapping: converts all features of a specific data type to another data type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6deaff88",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(tp.cast(node, {tp.float32: tp.str_, tp.float64: tp.int64}).features)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "915df6c5",
      "metadata": {
        "cell_marker": "\"\"\"",
        "lines_to_next_cell": 0
      },
      "source": [
        "\n",
        "Keep in mind that casting may fail when the graph is evaluated. For instance, attempting to cast `\"word\"` to `tp.float64` will result in an error. These errors cannot be caught prior to graph evaluation.\n",
        "\n",
        "## Arithmetic operators\n",
        "\n",
        "Arithmetic operators can be used between the features of an `EventSetNode`, to perform element-wise calculations.\n",
        "\n",
        "Common mathematical and bit operations are supported, such as addition (`+`), subtraction (`-`), product (`*`), division (`/`), floor division (`//`), modulo (`%`), comparisons (`>, >=, <, <=`), and bitwise operators (`&, |, ~`).\n",
        "\n",
        "These operators are applied index-wise and timestamp-wise, between features in the same position."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c673b17",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "outputs": [],
      "source": [
        "evset = tp.event_set(\n",
        "    timestamps=[1, 10],\n",
        "    features={\n",
        "        \"f1\": [0, 1],\n",
        "        \"f2\": [10.0, 20.0],\n",
        "        \"f3\": [100, 100],\n",
        "        \"f4\": [1000.0, 1000.0],\n",
        "    },\n",
        ")\n",
        "node = evset.node()\n",
        "\n",
        "node_added = node[[\"f1\", \"f2\"]] + node[[\"f3\", \"f4\"]]\n",
        "\n",
        "evset_added = node_added.run(evset)\n",
        "print(evset_added)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "03bd54cc",
      "metadata": {
        "cell_marker": "\"\"\"",
        "lines_to_next_cell": 0
      },
      "source": [
        "\n",
        "Note that features of type `int64` and `float64` are not mixed above, because otherwise the operation would fail without an explicit type cast."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "1675fa25",
      "metadata": {
        "cell_marker": "\"\"\"",
        "lines_to_next_cell": 0
      },
      "source": [
        "```python\n",
        "# Attempt to mix dtypes.\n",
        ">>> node[\"f1\"] + node[\"f2\"]\n",
        "Traceback (most recent call last):\n",
        "    ...\n",
        "ValueError: corresponding features should have the same dtype. ...\n",
        "```"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "7b50cf71",
      "metadata": {
        "cell_marker": "\"\"\"",
        "lines_to_next_cell": 0
      },
      "source": [
        "\n",
        "Refer to the [Casting](#casting) section for more on this.\n",
        "\n",
        "All the operators have an equivalent functional form. The example above using `+`, could be rewritten with `tp.add()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b350c4a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Equivalent.\n",
        "node_added = tp.add(node[[\"f1\", \"f2\"]], node[[\"f3\", \"f4\"]])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "d65bd8de",
      "metadata": {
        "cell_marker": "\"\"\"",
        "lines_to_next_cell": 0
      },
      "source": [
        "\n",
        "Other usual comparison and logic operators also work (except `==`, see below)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1462eea",
      "metadata": {},
      "outputs": [],
      "source": [
        "is_greater = node[[\"f1\", \"f2\"]] > node[[\"f3\", \"f4\"]]\n",
        "is_less_or_equal = node[[\"f1\", \"f2\"]] <= node[[\"f3\", \"f4\"]]\n",
        "is_wrong = is_greater & is_less_or_equal"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "9f01eee7",
      "metadata": {
        "cell_marker": "\"\"\"",
        "lines_to_next_cell": 0
      },
      "source": [
        "\n",
        "**Warning:** The Python equality operator (`==`) does not compute element-wise equality between features. Use the `tp.equal()` operator instead."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c610a0d0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Works element-wise as expected\n",
        "tp.equal(node[\"f1\"], node[\"f3\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abda404b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# This is just a boolean\n",
        "(node[\"f1\"] == node[\"f3\"])\n",
        "False"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "0fa4a2d1",
      "metadata": {
        "cell_marker": "\"\"\"",
        "lines_to_next_cell": 0
      },
      "source": [
        "\n",
        "All these operators act feature-wise, i.e. they perform index-feature-wise operations (for each feature in each index key). This implies that the input `EventSetNodes` must have the same number of features."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "0352b9de",
      "metadata": {
        "cell_marker": "\"\"\"",
        "lines_to_next_cell": 0
      },
      "source": [
        "```python\n",
        "node[[\"f1\", \"f2\"]] + node[\"f3\"]\n",
        "Traceback (most recent call last):\n",
        "    ...\n",
        "ValueError: The left and right arguments should have the same number of features. ...\n",
        "```"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "8dd1d7f4",
      "metadata": {
        "cell_marker": "\"\"\"",
        "lines_to_next_cell": 0
      },
      "source": [
        "\n",
        "The input `EventSetNodes` must also have the same sampling and index."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "00990d1e",
      "metadata": {
        "cell_marker": "\"\"\"",
        "lines_to_next_cell": 0
      },
      "source": [
        "```python\n",
        "sampling_1 = tp.event_set(\n",
        "    timestamps=[0, 1],\n",
        "    features={\"f1\": [1, 2]},\n",
        ")\n",
        "sampling_2 = tp.event_set(\n",
        "    timestamps=[1, 2],\n",
        "    features={\"f1\": [3, 4]},\n",
        ")\n",
        "sampling_1.node() + sampling_2.node()\n",
        "Traceback (most recent call last):\n",
        "    ...\n",
        "ValueError: Arguments should have the same sampling. ...\n",
        "```"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "217fa8f5",
      "metadata": {
        "cell_marker": "\"\"\"",
        "lines_to_next_cell": 0
      },
      "source": [
        "\n",
        "If you want to apply arithmetic operators on `EventSetNodes` with different samplings, take a look at\n",
        "[Sampling](#sampling) section.\n",
        "\n",
        "If you want to apply them on `EventSetNodes` with different indexes, check the\n",
        "[Vertical operators](#indexes-horizontal-and-vertical-operators) section.\n",
        "\n",
        "Operations involving scalars are applied index-feature-element-wise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58fe7d8e",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "outputs": [],
      "source": [
        "node_scalar = node * 10\n",
        "print(node_scalar.run(evset))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "a229408c",
      "metadata": {
        "cell_marker": "\"\"\"",
        "lines_to_next_cell": 0
      },
      "source": [
        "\n",
        "## Sampling\n",
        "\n",
        "Arithmetic operators, such as `tp.add()`, require their input arguments to have the same timestamps and [Index](#indexes-horizontal-and-vertical-operators). The unique combination of timestamps and indexes is called a _sampling_.\n",
        "\n",
        "<!-- TODO: example -->\n",
        "\n",
        "For example, if `EventSetNodes` `a` and `b` have different samplings, `a[\"feature_1\"] + b[\"feature_2\"]` will fail.\n",
        "\n",
        "To use arithmetic operators on `EventSets` with different samplings, one of the `EventSets` needs to be resampled to the sampling of the other `EventSet`. Resampling is done with the `tp.resample()` operator.\n",
        "\n",
        "The `tp.resample()` operator takes two `EventSets` called `input` and `sampling`, and returns the resampling of the features of `input` according to the timestamps of `sampling` according to the following rules:\n",
        "\n",
        "If a timestamp is present in `input` but not in `sampling`, the timestamp is dropped.\n",
        "If a timestamp is present in both `input` and `sampling`, the timestamp is kept.\n",
        "If a timestamp is present in `sampling` but not in `input`, a new timestamp is created using the feature values from the _closest anterior_ (not the closest, as that could induce future leakage) timestamp of `input`. This rule is especially useful for events that represent measurements (see [Events and `EventSets`](#events-and-eventsets)).\n",
        "\n",
        "**Note:** Features in `sampling` are ignored. This also happens in some other operators that take a `sampling` argument of type `EventSetNode` - it indicates that only the sampling (a.k.a. the indexes and timestamps) of that `EventSetNode` are being used by that operator.\n",
        "\n",
        "Given this example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "087b6fd6",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "outputs": [],
      "source": [
        "evset = tp.event_set(\n",
        "    timestamps=[10, 20, 30],\n",
        "    features={\n",
        "        \"x\": [1.0, 2.0, 3.0],\n",
        "    },\n",
        ")\n",
        "node = evset.node()\n",
        "sampling_evset = tp.event_set(\n",
        "    timestamps=[0, 9, 10, 11, 19, 20, 21],\n",
        ")\n",
        "sampling_node = sampling_evset.node()\n",
        "resampled = tp.resample(input=node, sampling=sampling_node)\n",
        "resampled.run({node: evset, sampling_node: sampling_evset})"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "11496f59",
      "metadata": {
        "cell_marker": "\"\"\"",
        "lines_to_next_cell": 0
      },
      "source": [
        "\n",
        "The following would be the matching between the timestamps of `sampling` and `input`:\n",
        "\n",
        "| `sampling` timestamp         | 0   | 9   | 10  | 11  | 19  | 20  | 21  |\n",
        "| ---------------------------- | --- | --- | --- | --- | --- | --- | --- |\n",
        "| matching `input` timestamp   | -   | -   | 10  | 10  | 10  | 20  | 20  |\n",
        "| matching `\"x\"` feature value | NaN | NaN | 1   | 1   | 1   | 2   | 2   |\n",
        "\n",
        "If `sampling` contains a timestamp anterior to any timestamp in the `input` (like 0 and 9 in the example above), the feature of the sampled event will be missing. The representation of a missing value depends on its dtype:\n",
        "\n",
        "float: `NaN`\n",
        "integer: `0`\n",
        "string: `\"\"`\n",
        "\n",
        "Back to the example of the `tp.add()` operator, `a` and `b` with different sampling can be added as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df3bbc7d",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "outputs": [],
      "source": [
        "sampling_a = tp.event_set(\n",
        "    timestamps=[0, 1, 2],\n",
        "    features={\"f1\": [10, 20, 30]},\n",
        ")\n",
        "sampling_b = tp.event_set(\n",
        "    timestamps=[1, 2, 3],\n",
        "    features={\"f1\": [5, 4, 3]},\n",
        ")\n",
        "a = sampling_a.node()\n",
        "b = sampling_b.node()\n",
        "result = a + tp.resample(b, a)\n",
        "result.run({a: sampling_a, b: sampling_b})"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "56313ff2",
      "metadata": {
        "cell_marker": "\"\"\"",
        "lines_to_next_cell": 0
      },
      "source": [
        "\n",
        "`tp.resample()` is critical to combine events from different, non-synchronized sources. For example, consider a system with two sensors, a thermometer for temperature and a manometer for pressure. The temperature sensor produces measurements every 1 to 10 minutes, while the pressure sensor returns measurements every second. Additionally assume that both sensors are not synchronized. Finally, assume that you need to combine the temperature and pressure measurements with the equation `temperature / pressure`.\n",
        "\n",
        "<!-- TODO: image -->\n",
        "\n",
        "Since the temperature and pressure `EventSets` have different sampling, you will need to resample one of them. The pressure sensor has higher resolution. Therefore, resampling the temperature to the pressure yields higher resolution than resampling the pressure to the temperature.\n",
        "\n",
        "```python\n",
        "r = tp.resample(termometer[\"temperature\"], manometer) / manometer[\"pressure\"]\n",
        "```"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "ae131e37",
      "metadata": {
        "cell_marker": "\"\"\"",
        "lines_to_next_cell": 0
      },
      "source": [
        "\n",
        "When handling non-uniform timestamps it is also common to have a common resampling source.\n",
        "\n",
        "```python\n",
        "sampling_source = # Uniform timestamps every 10 seconds.\n",
        "r = tp.resample(termometer[\"temperature\"], sampling_source) / tp.resample(manometer[\"pressure\"], sampling_source)\n",
        "```\n",
        "\n",
        "Moving window operators, such as the `tp.simple_moving_average()` or `tp.moving_count()` operators, have an optional `sampling` argument. For example, the signature of the simple moving average operator is `tp.simple_moving_average()(][temporian.simple_moving_average]input: EventSetNode, window_length: Duration, sampling: Optional[EventSetNode] = None)`. If `sampling`is not set, the result will maintain the sampling of the`input`argument. If`sampling`is set, the moving window will be sampled at each timestamp of`sampling` instead, and the result will have those new ones.\n",
        "\n",
        "```python\n",
        "b = tp.simple_moving_average(input=a, window_length=10)\n",
        "c = tp.simple_moving_average(input=a, window_length=10, sampling=d)\n",
        "```\n",
        "\n",
        "Note that if planning to resample the result of a moving window operator, passing the `sampling` argument is both more efficient and more accurate than calling `tp.resample()` on the result.\n",
        "\n",
        "## Indexes, horizontal and vertical operators\n",
        "\n",
        "All operators presented so far work on a sequence of related events. For instance, the simple moving average operator computes the average of events within a specific time window. These types of operators are called _horizontal operators_.\n",
        "\n",
        "It is sometimes desirable for events in an `EventSet` not to interact with each other. For example, assume a dataset containing the sum of daily sales of a set of products. The objective is to compute the sum of weekly sales of each product independently. In this scenario, the weekly moving sum should be applied individually to each product. If not, you would compute the weekly sales of all the products together.\n",
        "\n",
        "To compute the weekly sales of individual products, you can define the `product` feature as the _index_."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54a71cae",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "outputs": [],
      "source": [
        "daily_sales = tp.event_set(\n",
        "\ttimestamps=[\"2020-01-01\", \"2020-01-01\", \"2020-01-02\", \"2020-01-02\"],\n",
        "\tfeatures={\n",
        "        \"product\": [1, 2, 1, 2],\n",
        "        \"sale\": [100.0, 300.0, 90.0, 400.0],\n",
        "    },\n",
        "    indexes=[\"product\"]\n",
        ")\n",
        "print(daily_sales)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "40dacbb4",
      "metadata": {
        "cell_marker": "\"\"\"",
        "lines_to_next_cell": 0
      },
      "source": [
        "\n",
        "The moving sum operator will then be applied independently to the events corresponding to each product."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c87a680",
      "metadata": {
        "lines_to_next_cell": 2
      },
      "outputs": [],
      "source": [
        "a = daily_sales.node()\n",
        "\n",
        "# Compute the moving sum of each index group (a.k.a. each product) individually.\n",
        "b = tp.moving_sum(a, window_length=tp.duration.weeks(1))\n",
        "\n",
        "b.run({a: daily_sales})"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "e096897d",
      "metadata": {
        "cell_marker": "\"\"\"",
        "lines_to_next_cell": 0
      },
      "source": [
        "\n",
        "Horizontal operators can be understood as operators that are applied independently on each index.\n",
        "\n",
        "Operators that modify an `EventSetNode`'s indexes are called _vertical operators_. The most important vertical operators are:\n",
        "\n",
        "- `tp.add_index()`: Add features to the index.\n",
        "- `tp.drop_index()`: Remove features from the index, optionally keeping them as features.\n",
        "- `tp.set_index()`: Changes the index.\n",
        "- `tp.propagate()`: Expand indexes based on another `EventSet`s indexes.\n",
        "\n",
        "By default, `EventSets` are _flat_, which means they have no index, and therefore all events are in a single global group.\n",
        "\n",
        "Also, keep in mind that only string and integer features can be used as indexes.\n",
        "\n",
        "`EventSets` can have multiple features as index. In the next example, assume our daily sale aggregates are also annotated with `store` data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8badbebf",
      "metadata": {},
      "outputs": [],
      "source": [
        "daily_sales = tp.event_set(\n",
        "\ttimestamps=[\"2020-01-01\", \"2020-01-01\", \"2020-01-02\", \"2020-01-02\"],\n",
        "\tfeatures={\n",
        "        \"store\": [1, 1, 1, 2],\n",
        "        \"product\": [1, 2, 1, 2],\n",
        "        \"sale\": [100.0, 200.0, 110.0, 300.0],\n",
        "    },\n",
        ")\n",
        "print(daily_sales)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "69b3c03c",
      "metadata": {
        "cell_marker": "\"\"\"",
        "lines_to_next_cell": 0
      },
      "source": [
        "\n",
        "Since we haven't defined the `indexes` yet, `store` and `product` are just regular features above.\n",
        "Let's add the `(product, store)` pair as the index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "479096c3",
      "metadata": {
        "lines_to_next_cell": 2
      },
      "outputs": [],
      "source": [
        "a = daily_sales.node()\n",
        "b = tp.add_index(a, [\"product\", \"store\"])\n",
        "b.run({a: daily_sales})"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "c2dc98f6",
      "metadata": {
        "cell_marker": "\"\"\"",
        "lines_to_next_cell": 0
      },
      "source": [
        "\n",
        "The `moving_sum` operator can be used to calculate the weekly sum of sales\n",
        "for each `(product, store)` pair."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4df0d8cf",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "outputs": [],
      "source": [
        "# Weekly sales by product and store\n",
        "c = tp.moving_sum(b[\"sale\"], window_length=tp.duration.weeks(1))\n",
        "c.run({a: daily_sales})"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "2295d4ee",
      "metadata": {
        "cell_marker": "\"\"\"",
        "lines_to_next_cell": 0
      },
      "source": [
        "\n",
        "If we want the weekly sum of sales per `store`, we can just drop the `product` index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d9448a2",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "outputs": [],
      "source": [
        "# Weekly sales by store (including all products)\n",
        "d = tp.drop_index(b, \"product\")\n",
        "e = tp.moving_sum(d[\"sale\"], window_length=tp.duration.weeks(1))\n",
        "e.run({a: daily_sales})"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "f67b3f0c",
      "metadata": {
        "cell_marker": "\"\"\"",
        "lines_to_next_cell": 0
      },
      "source": [
        "\n",
        "Finally, let's calculate the ratio of sales of each `(product, store)` pair compared to the whole `store` sales.\n",
        "\n",
        "Since `c` (weekly sales for each product and store) and `e` (weekly sales for each store) have different indexes, we cannot use `tp.divide` (or `/`) directly - we must first `propagate` `e` to the `[\"product\", \"store\"]` index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e12a9e0",
      "metadata": {
        "lines_to_next_cell": 0
      },
      "outputs": [],
      "source": [
        "# Copy the content of e (indexed by (store)) into each (store, product).\n",
        "f = c / tp.propagate(e, sampling=c, resample=True)\n",
        "\n",
        "# Equivalent.\n",
        "f = c / tp.resample(\n",
        "    tp.propagate(e, sampling=c),\n",
        "    sampling=c,\n",
        ")\n",
        "print(f.run({a: daily_sales}))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "e73da62c",
      "metadata": {
        "cell_marker": "\"\"\"",
        "lines_to_next_cell": 0
      },
      "source": [
        "\n",
        "The `tp.propagate()` operator expands the indexes of its `input` (`e` in this case) to match the indexes of its `sampling` by copying the content of `input` into each corresponding index group of `sampling`. Note that `sampling`'s indexes must be a superset of `input`'s indexes.\n",
        "\n",
        "## Future leakage\n",
        "\n",
        "In supervised learning, [leakage](<https://en.wikipedia.org/wiki/Leakage_(machine_learning)>) is the use of data not available at serving time by a machine learning model. A common example of leakage is _label leakage_, which involves the invalid use of labels in the model input features. Leakage tends to bias model evaluation by making it appear much better than it is in reality. Unfortunately, leakage is often subtle, easy to inject, and challenging to detect.\n",
        "\n",
        "Another type of leakage is future leakage, where a model uses data before it is available. Future leakage is particularly easy to create, as all feature data is ultimately available to the model, the problem being it being accessed at the wrong time.\n",
        "\n",
        "To avoid future leakage, Temporian operators are guaranteed to not cause future leakage, except for the `tp.leak()` operator. This means that it is impossible to inadvertently add future leakage to a Temporian program.\n",
        "\n",
        "`tp.leak()` can be useful for precomputing labels or evaluating machine learning models. However, its outputs shouldnt be used as input features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c07453fa",
      "metadata": {},
      "outputs": [],
      "source": [
        "a = tp.input_node(features=[(\"feature_1\", tp.float32)])\n",
        "b = tp.moving_count(a, 1)\n",
        "c = tp.moving_count(tp.leak(b, 1), 2)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "8d973547",
      "metadata": {
        "cell_marker": "\"\"\"",
        "lines_to_next_cell": 0
      },
      "source": [
        "\n",
        "In this example, `b` does not have a future leak, but `c` does because it depends on `tp.leak()`.\n",
        "\n",
        "<!-- TODO: Not implemented yet\n",
        "\n",
        "To check programmatically if a `Node` depends on `tp.leak()`, we can use the `tp.has_leak()` function.\n",
        "\n",
        "# print(tp.has_leak(b))\n",
        "# False\n",
        "\n",
        "# print(tp.has_leak(c))\n",
        "# True\n",
        "\n",
        "\n",
        "By using `tp.has_leak()`, we can programmatically identify future leakage and modify our code accordingly.\n",
        "-->\n",
        "\n",
        "## Accessing `EventSet` data\n",
        "\n",
        "`EventSet` data can be accessed using their `data` attribute. Temporian internally relies on NumPy, which means that the data access functions always return NumPy arrays."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7da63117",
      "metadata": {},
      "outputs": [],
      "source": [
        "evset = tp.event_set(\n",
        "\ttimestamps=[1, 2, 3, 5, 6],\n",
        "\tfeatures={\n",
        "        \"f1\": [0.1, 0.2, 0.3, 1.1, 1.2],\n",
        "        \"f2\": [\"red\", \"red\", \"red\", \"blue\", \"blue\"],\n",
        "\t},\n",
        "\tindexes=[\"f2\"],\n",
        ")\n",
        "\n",
        "# Access the data for the index group `f2=red`.\n",
        "evset.data[(\"red\",)]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "eddfa88e",
      "metadata": {
        "cell_marker": "\"\"\"",
        "lines_to_next_cell": 0
      },
      "source": [
        "\n",
        "<!--\n",
        "`EventSet` data can be accessed using the `index()` and `feature()` functions. Temporian internally relies on NumPy, which means that the data access functions always return NumPy arrays.\n",
        "\n",
        "evset = tp.event_set(\n",
        "\ttimestamps=[1, 2, 3, 5, 6],\n",
        "\tfeatures={\n",
        "        \"f1\": [0.1, 0.2, 0.3, 1.1, 1.2],\n",
        "        \"f2\": [\"red\", \"red\", \"red\", \"blue\", \"blue\"],\n",
        "\t},\n",
        "\tindexes=[\"f2\"],\n",
        ")\n",
        "\n",
        "# Access the data for the index group `f2=red`.\n",
        "evset.index(\"red\")\n",
        "\n",
        "\n",
        "# Equivalent.\n",
        "evset.index((\"red\", ))\n",
        "\n",
        "\n",
        "# Access the data for the index group `f2=red` and feature `f1`.\n",
        "evset.index(\"red\").feature(\"f1\")\n",
        "\n",
        "\n",
        "If an `EventSet` does not have an index, `feature` can be called directly:\n",
        "\n",
        "evset = tp.event_set(\n",
        "\ttimestamps=[1, 2, 3, 5, 6],\n",
        "\tfeatures={\n",
        "        \"f1\": [0.1, 0.2, 0.3, 1.1, 1.2],\n",
        "        \"f2\": [\"red\", \"red\", \"red\", \"blue\", \"blue\"],\n",
        "\t},\n",
        ")\n",
        "evset.feature(\"f1\")\n",
        "-->\n",
        "\n",
        "## Import and export data\n",
        "\n",
        "`EventSets` can be read from and saved to csv files via the `tp.from_csv()` and `tp.to_csv()` functions.\n",
        "\n",
        "# Read EventSet from a .csv file.\n",
        "\n",
        "```python\n",
        "evset = tp.from_csv(\n",
        "    path=\"path/to/file.csv\",\n",
        "    timestamps=\"timestamp\",\n",
        "    indexes=[\"product_id\"],\n",
        ")\n",
        "\n",
        "# Save EventSet to a .csv file.\n",
        "tp.to_csv(evset, path=\"path/to/file.csv\")\n",
        "```\n",
        "\n",
        "Converting `EventSet` data to and from pandas DataFrames is also easily done via `tp.to_pandas()` and `tp.from_pandas()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da239494",
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.DataFrame({\n",
        "    \"timestamp\": [1, 2, 3, 5, 6],\n",
        "    \"f1\": [0.1, 0.2, 0.3, 1.1, 1.2],\n",
        "    \"f2\": [\"red\", \"red\", \"red\", \"blue\", \"blue\"],\n",
        "})\n",
        "\n",
        "# Create EventSet from DataFrame.\n",
        "evset = tp.from_pandas(df)\n",
        "\n",
        "# Convert EventSet to DataFrame.\n",
        "df = tp.to_pandas(evset)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "a96084af",
      "metadata": {
        "cell_marker": "\"\"\"",
        "lines_to_next_cell": 0
      },
      "source": [
        "\n",
        "## Serialization and deserialization of a graph\n",
        "\n",
        "Temporian graphs can be exported and imported to a safe-to-share file with `tp.save_graph()` and `tp.load_graph()`. In both functions input and output `EventSetNodes` need to be named, or be assigned a name by passing them as a dictionary.\n",
        "\n",
        "```python\n",
        "# Define a graph.\n",
        "evset = tp.event_set(\n",
        "\ttimestamps=[1, 2, 3],\n",
        "\tfeatures={\"f1\": [0.1, 0.2, 0.3]},\n",
        ")\n",
        "a = evset.node()\n",
        "b = tp.moving_count(a, 1)\n",
        "\n",
        "# Save the graph.\n",
        "tp.save_graph(inputs={\"input_a\": a}, outputs={\"output_b\": b}, path=\"/tmp/my_graph.tem\")\n",
        "\n",
        "# Equivalent.\n",
        "a.name = \"input_a\"\n",
        "b.name = \"output_b\"\n",
        "tp.save_graph(inputs=a, outputs=[b], path=\"/tmp/my_graph.tem\")\n",
        "\n",
        "# Load the graph.\n",
        "loaded_inputs, loaded_outputs = tp.load_graph(path=\"/tmp/my_graph.tem\")\n",
        "\n",
        "# Run data on the restored graph.\n",
        "tp.run(loaded_outputs[\"output_b\"], {loaded_inputs[\"input_a\"]: evset})\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56a28657",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
